# -*- coding: utf-8 -*-
"""Mini_Proj_CNN.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1-FYs5JY2P9b_ijLCVZidkNRi0nDJIdvu
"""

import numpy as np
import pandas as pd
import os
import zipfile
import cv2
import torch
import torch.nn as nn
import matplotlib.pyplot as plt
from google.colab import drive
import torchvision
import torchvision.transforms as transforms
import torchvision.datasets as datasets
from torch.utils.data import DataLoader
from torchsummary import summary
import torch.optim as optim
from tqdm.notebook import tqdm
from numba import jit
from sklearn.metrics import confusion_matrix
import seaborn as sn

#connect drive
drive.mount('/content/drive/')

#unpack zip from drive
with zipfile.ZipFile("drive/MyDrive/clean_data.zip","r") as zip_ref:
    zip_ref.extractall("./")
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
print(device)

disease_lables = ('Bactiral Pneunomia', 'Viral Pneunomia')
normal_lable = ('Normal')
def to_location_modified(target):
    NUM_CLASS = len(disease_lables) + 1 
    one_hot = torch.eye(NUM_CLASS)[target]
    return one_hot

#data aug
train_data_path = "data/train"
test_data_path = "data/test"
BATCH_SIZE = 32

train_transforms = transforms.Compose([transforms.Resize((150, 150)),transforms.Grayscale(),
                                       transforms.ToTensor(),transforms.RandomHorizontalFlip(),
                                       transforms.RandomVerticalFlip(),transforms.RandomRotation(45)])

test_transforms = transforms.Compose([transforms.Resize((150,150)),transforms.Grayscale(),transforms.ToTensor()])


train_data = datasets.ImageFolder(train_data_path, transform=train_transforms, target_transform=to_location_modified)
test_data = datasets.ImageFolder(test_data_path, transform=test_transforms, target_transform=to_location_modified)

#load test/train data
train_dl = torch.utils.data.DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True)
test_dl = torch.utils.data.DataLoader(test_data, batch_size=BATCH_SIZE, shuffle=True)

plt.figure(figsize=(15,5))
images, labels = iter(train_dl).next()
def imshow(img):
    npimg = img.numpy()
    plt.imshow(np.transpose(npimg, (1, 2, 0)))
    plt.show()
imshow(torchvision.utils.make_grid(images))

class CNN(nn.Module):
    def __init__(self, input_channels, n_classes):
        super(CNN, self).__init__()
        self.conv_layers = nn.Sequential(
            nn.Conv2d(in_channels=input_channels, out_channels=16, kernel_size=3),
            nn.ReLU(),
            nn.BatchNorm2d(16),
            nn.Conv2d(in_channels=16, out_channels=16, kernel_size=3),
            nn.ReLU(),
            nn.BatchNorm2d(16),
            nn.MaxPool2d(kernel_size=2),

            nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3),
            nn.ReLU(),
            nn.BatchNorm2d(32),
            nn.Conv2d(in_channels=32, out_channels=32, kernel_size=3),
            nn.ReLU(),
            nn.BatchNorm2d(32),
            nn.MaxPool2d(kernel_size=2),

            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3),
            nn.ReLU(),
            nn.BatchNorm2d(64),
            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3),
            nn.ReLU(),
            nn.BatchNorm2d(64),
            nn.MaxPool2d(kernel_size=2),

            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3),
            nn.ReLU(),
            nn.BatchNorm2d(128),
            nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3),
            nn.ReLU(),
            nn.BatchNorm2d(128),
            nn.MaxPool2d(kernel_size=2),
        )

        self.fc = nn.Sequential(
            nn.Flatten(),
            nn.Linear(128*5*5, 4096),
			nn.ReLU(),
			nn.Dropout(.5),
			nn.Linear(4096, 4096),
			nn.ReLU(),
			nn.Dropout(.5),
			nn.Linear(4096, n_classes),
            nn.Softmax(dim=1)
        )

    def forward(self, x):
        x = self.conv_layers(x)
        x = self.fc(x)
        return x

model = CNN(input_channels=1, n_classes=3).to(device)

model.conv_layers(images[:1].to(device)).size()

summary(model,(1,150,150))

def val(data_dl, model):
    model.eval()
    with torch.no_grad():
        correct = 0
        total = 0
        for images, labels in data_dl:
            images = images.to(device)
            outputs = model(images)
            for out, label in zip(outputs, labels):
                if torch.argmax(out) == torch.argmax(label):
                    correct += 1
                
            total += len(outputs)
        acc = correct/total
        return acc
print(val(test_dl, model))

criterion = nn.BCELoss()
optimizer = optim.Adam(model.parameters(), lr=3e-4)
scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=3)

EPOCHS = 32
test_accs = []
losses = []
max_acc = 0

for epoch in range(EPOCHS):
    losses_sh = []
    for i, (images, labels) in tqdm(enumerate(train_dl)):
        images = images.to(device)
        labels = labels.to(device)
        
        preds = model(images)
        nn.functional.one_hot(preds.argmax(1), 3)
        loss = criterion(preds, labels)

        optimizer.zero_grad()
        loss.backward()
        optimizer.step()


        losses.append(loss.item())
        losses_sh.append(loss.item())

        if i%10 == 0:
            test_acc = val(test_dl, model)
            test_accs.append(test_acc)
            if test_acc >= .87 and test_acc > max_acc and loss.item() < 0.1:
                max_acc = test_acc
                model.cpu()
                print('\ntest acc', test_acc, ' loss: ', loss.item(), ' saving model...')
                torch.save(model, f"drive/MyDrive/MINI_proj/{test_acc}_loss{loss.item():.3f}.pt")
                model.cuda()

    mean_loss = sum(losses_sh)/len(losses_sh)
    scheduler.step(mean_loss)

    test_acc = val(test_dl, model)
    plt.plot(test_accs)
    plt.show()

    print(f"\n### EPOCH: {epoch+1}, MeanLoss: {mean_loss}, Test Acc: {test_acc}\n\n")